{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Ground Truth One Shot Notebook\n",
    "*Written by xavtidus@ with incredible help and input from (and a big thank you to): atlynch@, djenny@ and benhuan@.*\n",
    "## Train your completed Ground Truth labelling job in no time\n",
    "\n",
    "### Why we made this notebook\n",
    "The intention behind this notebook is to allow anyone to input the name of their Sagemaker Ground Truth Labelling Job, and immediately be able to start training that model and consume it. We've attempted to take away all the complications behind finding the right prameter inputs and items of information needed that can be spread over a number of config and manifest files and build a tool that can determine them by crawling forward from the Sagemaker Ground Truth Labelling Job's name.\n",
    "\n",
    "If you're interested in the subject, you will be able to follow along below and see where the code is grabbing what information and where from. A lot of the time, code is easier to interpret than the instruction manual, and we indeed hope that is the case here.\n",
    "\n",
    "If you're just looking for a quick outcome, this notebook is also perfect for you. There are definitely performance improvements that could be made to your model's training, however this notebook will get you a workable outcome as long as the input imagery in Sagemaker is good quality.\n",
    "\n",
    "## A quick technical note\n",
    "\n",
    "This notebook has to be executed on a SageMaker notebook instance. It will easily help you train a model straight from the completed output of a Sagemaker Ground Truth labelling job, with no prior knowledge required.\n",
    "\n",
    "*If you are asked to choose a kernel for this notebook, choose \"conda_mxnet_p36\" or \"MXNet 1.6 Python 3.6\"*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurables\n",
    "\n",
    "There is only one required configurable for this notebook, and that's the name of your Sagemaker Ground Truth Labelling Job which should be completed already. There are however, some optional configurables in the next cell should you wish to get a little adventurous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_groundtruth_labelling_job_name = \"awsdltv2FinalApproach\"\n",
    "\n",
    "# This script will automatically crawl this job for all the related manifest files to derrive \n",
    "# the remaining items of configuration about your training data, labels and S3 paths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the optional configurables should you wish to customise your training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 20\n",
    "learning_rate = 0.001\n",
    "training_instance_type='ml.p2.8xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! From here on in, we will annotate code of interest with code comments for your information. Continue through all the steps to finish training your Sagemaker model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start training.\n",
    "\n",
    "First we will install the dependencies needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gluoncv==0.8.0\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will declare our imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "import gluoncv as gcv\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import tarfile\n",
    "import boto3\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker.mxnet import MXNet, MXNetModel\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from gluoncv import model_zoo, data, utils\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will determine the Sagemaker Service role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to start automatically resolving information such as the training data manifest, output ground truth annotations manifest, the class labels used in training and the label attribute name for the training job (not always the same as the name you gave the job when you created it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a SageMaker Boto3 client to do some lookups\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "#query the SM GT Labelling Job by Name\n",
    "response = sm_client.describe_labeling_job(\n",
    "    LabelingJobName=sm_groundtruth_labelling_job_name\n",
    ")\n",
    "\n",
    "sm_gt_manifest_file_s3_path = response[\"LabelingJobOutput\"][\"OutputDatasetS3Uri\"]\n",
    "sm_gt_source_frames_manifest_s3_path = response[\"InputConfig\"][\"DataSource\"][\"S3DataSource\"][\"ManifestS3Uri\"]\n",
    "sm_gt_label_category_config_s3_path = response[\"LabelCategoryConfigS3Uri\"]\n",
    "\n",
    "source_training_frames_s3_prefix = '/'.join(sm_gt_source_frames_manifest_s3_path.split('/')[:-1])\n",
    "ground_truth_manifest_s3_prefix = '/'.join(sm_gt_manifest_file_s3_path.split('/')[:-1])\n",
    "\n",
    "# define an s3 client for some s3 operations\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "#let's grab the config json file that contains all our labels for this Ground Truth job and build our classes array\n",
    "sm_gt_classes = []\n",
    "\n",
    "_bucketName = sm_gt_label_category_config_s3_path.split('/')[2]\n",
    "_keyPath = '/'.join(sm_gt_label_category_config_s3_path.split('/')[3:])\n",
    "response = s3_client.get_object(\n",
    "    Bucket=_bucketName,\n",
    "    Key=_keyPath\n",
    ")\n",
    "_label_cfg_file = json.loads(response['Body'].read().decode('utf-8'))\n",
    "\n",
    "for label in _label_cfg_file[\"labels\"]:\n",
    "    sm_gt_classes.append(label[\"label\"])\n",
    "            \n",
    "#Now we need to grab the manifest file from S3 to determine the \"Label Attribute Name\" for this labelling job, as it can be different from what the name is in Ground Truth\n",
    "_bucketName = sm_gt_manifest_file_s3_path.split('/')[2]\n",
    "_keyPath = '/'.join(sm_gt_manifest_file_s3_path.split('/')[3:])\n",
    "response = s3_client.get_object(\n",
    "    Bucket=_bucketName,\n",
    "    Key=_keyPath\n",
    ")\n",
    "manifest_file_body = response['Body'].read().decode('utf-8')\n",
    "manifest_line_0 = manifest_file_body.split('\\n')[0]\n",
    "_m_obj = json.loads(manifest_line_0)\n",
    "\n",
    "#We have now found the label attribute name for this manifest file.\n",
    "labelAttributeName = list(_m_obj.keys())[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will grab the preview image from your training set and overlay the applicable detection regions found by your annotators to preview the datasets and make sure we're about to start training with the right data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info = []\n",
    "\n",
    "lines = manifest_file_body.strip().split('\\n')\n",
    "for line in lines:\n",
    "    image_info.append(json.loads(line))\n",
    "\n",
    "info = image_info[0]\n",
    "\n",
    "class_map = info[f'{labelAttributeName}-metadata']['class-map']\n",
    "img_bucket = info['source-ref'].split('/')[2]\n",
    "img_filename = info['source-ref'].split('/')[-1]\n",
    "img_s3_path = \"/\".join(info['source-ref'].split('/')[3:])\n",
    "\n",
    "s3_client.download_file(img_bucket, img_s3_path, \"source-ref/\"+img_filename)\n",
    "\n",
    "image = plt.imread(os.path.join(\"source-ref\",img_filename))\n",
    "saved_image = image.copy() #Save an unmanipulated reference to the image\n",
    "boxes = info[labelAttributeName]['annotations']\n",
    "for box in boxes:\n",
    "    cv2.rectangle(image, (int(box['left']), int(box['top'])), (int(box['left']+box['width']), int(box['top']+box['height'])), (0,255,0), 3)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, it's time to create our MXNet Estimator and submit the job for training with Sagemaker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxnet_estimator = MXNet(entry_point='estimator.py',\n",
    "                        source_dir='entry_point',\n",
    "                        role=role,\n",
    "                        train_instance_type=training_instance_type,\n",
    "                        train_instance_count=1,\n",
    "                        sagemaker_session=sagemaker_session,\n",
    "                        framework_version='1.6.0', \n",
    "                        py_version='py3',\n",
    "                        hyperparameters={\n",
    "                            \"task-name\": labelAttributeName,\n",
    "                            \"classes-csv\": \",\".join(sm_gt_classes),\n",
    "                            \"target-epochs\": training_epochs,\n",
    "                            \"learning-rate\": learning_rate\n",
    "                        })\n",
    "\n",
    "mxnet_estimator.fit({'train': source_training_frames_s3_prefix, 'labels': ground_truth_manifest_s3_prefix})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's it! Now you can download and run your model locally.\n",
    "\n",
    "Optionally, you can continue on and deploy a Sagemaker Inference Endpoint, which is a fully managed service that allows you to make real-time inferences via a REST API. Great for internet connected projects that have low grade compute which wouldn't otherwise be able to run its own inference models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visit the AWS Console to download your newly trained model.\n",
    "Be sure to double check the region the console is set to if you do not immediately see your model in the list.\n",
    "\n",
    "In the [AWS Console, navigate to Amazon Sagemaker](https://console.aws.amazon.com/sagemaker/home), then in the left-hand menu expand \"Training\" and click \"Training Jobs\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy a Amazon Sagemaker Inference Endpoint\n",
    "\n",
    "This will enable you to deploy a fully managed service that allows you to make real-time inferences via a REST API. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you like, you can adjust the below parameter to a different compute instance type for your Inference Endpoint\n",
    "sm_i_endpoint_instance_type = 'ml.m5.xlarge'\n",
    "\n",
    "#You can also change the initial amount of instances for your endpoint\n",
    "sm_i_initial_instance_count = 1\n",
    "\n",
    "#The code below will generate a endpoint name for you based on the values previously, but you can change it to something else if you like.\n",
    "sm_i_endpoint_name = \"%s-%s\" % ( sm_groundtruth_labelling_job_name, ''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(6)) )\n",
    "\n",
    "predictor = mxnet_estimator.deploy(\n",
    "            instance_type=sm_i_endpoint_instance_type, \n",
    "            initial_instance_count=sm_i_initial_instance_count,\n",
    "            endpoint_name=sm_i_endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model using the Sagemaker Inference Endpoint\n",
    "Let's test out our model with some of our images we used in training. \n",
    "\n",
    "First we need some code to load and fetch images from S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set our images working directory\n",
    "images_working_dir = \"test-images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_fetch_image(s3_uri, working_dir):\n",
    "    _bucket = s3_uri.split('/')[2]\n",
    "    _filename = s3_uri.split('/')[-1]\n",
    "    _s3_path = \"/\".join(s3_uri.split('/')[3:])\n",
    "    \n",
    "    if os.path.exists(working_dir) == False:\n",
    "        os.makedirs(working_dir)\n",
    "    \n",
    "    s3_client.download_file(_bucket, _s3_path, working_dir+_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need some code that will draw boxes onto our image files to represent the detections of our model's inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_detection_boxes(working_dir, sm_endpoint_name):\n",
    "    runtime = boto3.client('runtime.sagemaker')\n",
    "    client = boto3.client('sagemaker')\n",
    "\n",
    "    gluoncv_endpoint = None\n",
    "    \n",
    "    for endpoint in  client.list_endpoints()['Endpoints']:\n",
    "        if endpoint[\"EndpointName\"] == sm_endpoint_name:\n",
    "            gluoncv_endpoint = endpoint\n",
    "        \n",
    "    eval_images = glob.glob(working_dir+\"*\")\n",
    "    n_images = len(eval_images)\n",
    "    cols = (int(math.sqrt(n_images)))*2\n",
    "\n",
    "    fig = plt.figure(figsize = (20,5))\n",
    "    imgs = []\n",
    "    for n, (image) in enumerate(eval_images[:n_images]):\n",
    "        orig_img = cv2.imread(image)\n",
    "        orig_img = cv2.resize(orig_img, (512,512))\n",
    "        img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        payload = json.dumps(img.tolist())\n",
    "        response = runtime.invoke_endpoint(EndpointName = gluoncv_endpoint['EndpointName'],\n",
    "                                           Body = payload)\n",
    "        response_body = response['Body']\n",
    "        result = json.loads(response_body.read().decode())\n",
    "        [class_IDs, scores, bounding_boxes] = result\n",
    "\n",
    "        bounding_boxes, scores, class_IDs =  mx.nd.array(bounding_boxes), mx.nd.array(scores), mx.nd.array(class_IDs)\n",
    "        ax = utils.viz.cv_plot_bbox(orig_img, bounding_boxes[0], scores[0], class_IDs[0], thresh=0.6, class_names=[\"AWS\"])\n",
    "\n",
    "        imgs.append(orig_img)   \n",
    "\n",
    "    w = 10\n",
    "    h = 10\n",
    "    fig = plt.figure(figsize = (100, 100))\n",
    "    columns = 1\n",
    "    rows = 2\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(cv2.cvtColor(imgs[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's grab 6 random shots from our training manifest and see what our model finds within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First empty our images folder\n",
    "if os.path.exists(images_working_dir): #if it doesn't yet exist, the downloader function will create it\n",
    "    for file in glob.glob(images_working_dir+\"*\"):\n",
    "        os.remove(file)\n",
    "\n",
    "#Next, grab our training items\n",
    "training_set_items = manifest_file_body.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Then grab a random sample of training images\n",
    "random_sample_set = random.sample(training_set_items, 6)\n",
    "\n",
    "#download each file into our working dir\n",
    "for sample in random_sample_set:\n",
    "    s3_fetch_image(json.loads(sample)[\"source-ref\"], images_working_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the results\n",
    "draw_detection_boxes(images_working_dir, sm_i_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminating the Amazon Sagemaker Inference Endpoint\n",
    "When you're done with your experiment, you can terminate your endpoint to save on usage costs by running the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletes the endpoint with the name set in the previous code cell\n",
    "sagemaker.Session().delete_endpoint(sm_i_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (MXNet 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/mxnet-1.6-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
